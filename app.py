# app.py
"""
Streamlit ä¸»åº”ç”¨æ–‡ä»¶
"""

import streamlit as st
import os
import pandas as pd
import io
from core.knowledge_base import KnowledgeBaseManager
from core.llm_integrator import LLMIntegrator
from core.rag_chain import create_rag_chain

# --- é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="AI-TGA æ™ºèƒ½æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå¹³å°",
    page_icon="ğŸ§ª",
    layout="wide",
    initial_sidebar_state="expanded",
)

# --- ä¸»æ ‡é¢˜ ---
st.title("ğŸ¤– AI-TGA: æ™ºèƒ½æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå¹³å°")





# --- åˆå§‹åŒ– session state ---
# ç”¨äºåœ¨é¡µé¢åˆ·æ–°é—´ä¿æŒçŠ¶æ€
if 'model_settings' not in st.session_state:
    st.session_state.model_settings = {
        'provider': 'Ollama',
        'api_key': '',
        'base_url': 'http://127.0.0.1:11434'
    }

# --- å¸¸é‡å®šä¹‰ ---
KNOWLEDGE_BASE_DIR = "knowledge_files"
CHROMA_DB_DIR = os.path.join("db", "chroma_db")

# ç¡®ä¿ç›®å½•å­˜åœ¨
os.makedirs(KNOWLEDGE_BASE_DIR, exist_ok=True)
os.makedirs(CHROMA_DB_DIR, exist_ok=True)


# --- æ ¸å¿ƒé€»è¾‘å‡½æ•° ---
@st.cache_resource
def get_kb_manager():
    """ç¼“å­˜çŸ¥è¯†åº“ç®¡ç†å™¨å®ä¾‹"""
    return KnowledgeBaseManager(knowledge_base_dir=KNOWLEDGE_BASE_DIR, chroma_db_dir=CHROMA_DB_DIR)

# --- æ¸…ç†å‡½æ•° ---
def cleanup_directories():
    """æ¸…ç†çŸ¥è¯†åº“å’Œæ•°æ®åº“ç›®å½•"""
    import shutil
    # åœæ­¢å¹¶ç­‰å¾…æ–‡ä»¶é‡Šæ”¾
    if os.path.exists(KNOWLEDGE_BASE_DIR):
        shutil.rmtree(KNOWLEDGE_BASE_DIR, ignore_errors=True)
    if os.path.exists(CHROMA_DB_DIR):
        shutil.rmtree(CHROMA_DB_DIR, ignore_errors=True)
    
    # çŸ­æš‚ç­‰å¾…ä»¥ç¡®ä¿æ–‡ä»¶å¥æŸ„è¢«é‡Šæ”¾
    import time
    time.sleep(1)

    os.makedirs(KNOWLEDGE_BASE_DIR, exist_ok=True)
    os.makedirs(CHROMA_DB_DIR, exist_ok=True)
    
    # é‡ç½®ç¼“å­˜å’ŒçŠ¶æ€
    st.cache_resource.clear()
    st.session_state.knowledge_base_status = {
        "status": "å·²é‡ç½®",
        "doc_count": 0,
        "chunk_count": 0,
    }

if 'generated_cases' not in st.session_state:
    st.session_state.generated_cases = None

if 'knowledge_base_status' not in st.session_state:
    kb_manager = get_kb_manager()
    status = kb_manager.get_status()
    st.session_state.knowledge_base_status = {
        "status": "å·²åŠ è½½",
        "doc_count": status['doc_count'],
        "chunk_count": status['chunk_count'],
    }

# --- åˆ›å»ºä¸»é¡µé¢æ ‡ç­¾ ---
tab_generate, tab_kb, tab_settings = st.tabs([
    "ğŸ“„ ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹", 
    "ğŸ“š çŸ¥è¯†åº“ç®¡ç†", 
    "âš™ï¸ æ¨¡å‹è®¾ç½®"
])


# --- é¡µé¢ä¸€ï¼šç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ ---
with tab_generate:
    st.header("åœ¨è¿™é‡Œæ ¹æ®æ‚¨çš„éœ€æ±‚ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹")
    
    # --- ä¾§è¾¹æ  ---
    with st.sidebar:
        st.header("ç”Ÿæˆå‚æ•°é…ç½®")
        
        user_requirement = st.text_area("1. è¾“å…¥æ‚¨çš„éœ€æ±‚æè¿°", height=200, placeholder="ä¾‹å¦‚ï¼šè®¾è®¡ä¸€ä¸ªç”¨æˆ·ç™»å½•åŠŸèƒ½çš„æµ‹è¯•ç”¨ä¾‹ï¼Œéœ€è¦è€ƒè™‘æ­£å¸¸ç™»å½•ã€å¼‚å¸¸å¯†ç ã€é”å®šç­–ç•¥ç­‰åœºæ™¯ã€‚")
        
        uploaded_file = st.file_uploader("2. (å¯é€‰) ä¸Šä¼ éœ€æ±‚æ–‡æ¡£", type=['txt', 'pdf', 'docx', 'xlsx'])
        
        st.write("---")
        
        num_cases = st.slider("3. ç”Ÿæˆæœ€å¤§ç”¨ä¾‹æ•°é‡", min_value=1, max_value=20, value=5)
        
        temperature = st.slider("4. AI åˆ›é€ æ€§ (Temperature)", min_value=0.0, max_value=1.0, value=0.7, step=0.1, help="å€¼è¶Šé«˜ï¼Œç”Ÿæˆç»“æœè¶Šéšæœºå’Œæœ‰åˆ›æ„ï¼›å€¼è¶Šä½ï¼Œç»“æœè¶Šç¡®å®šå’Œä¿å®ˆã€‚")
        
        use_kb = st.checkbox("5. ä½¿ç”¨çŸ¥è¯†åº“å¢å¼ºç”Ÿæˆ", value=True)
        
        st.write("---")
        
        # ä» session_state è·å–å½“å‰æ¨¡å‹ç”¨äºæ˜¾ç¤º
        current_model_provider = st.session_state.model_settings.get('provider', 'N/A')
        st.info(f"å½“å‰LLM: **{st.session_state.model_settings.get('model_name', 'qwen3:4b')}**")
        st.info(f"å½“å‰Embedding: **dengcao/Qwen3-Embedding-0.6B:Q8_0**")

        if st.button("ğŸš€ ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹", type="primary", use_container_width=True):
            if not user_requirement and not uploaded_file:
                st.warning("è¯·è¾“å…¥éœ€æ±‚æè¿°æˆ–ä¸Šä¼ éœ€æ±‚æ–‡æ¡£ã€‚")
            else:
                with st.spinner("æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹å’ŒçŸ¥è¯†åº“..."):
                    try:
                        # 1. åˆå§‹åŒ–LLM
                        model_settings = st.session_state.model_settings
                        llm_integrator = LLMIntegrator(
                            model_provider=model_settings['provider'],
                            model_name=st.session_state.model_settings.get('model_name', 'qwen3:4b'),
                            api_key=model_settings['api_key'],
                            base_url=model_settings['base_url']
                        )
                        llm = llm_integrator.get_llm()

                        # 2. åˆå§‹åŒ–Retriever
                        kb_manager = get_kb_manager()
                        retriever = kb_manager.get_retriever()
                        
                        # 3. å¤„ç†ç”¨æˆ·è¾“å…¥
                        full_requirement = user_requirement
                        if uploaded_file:
                            # è¯»å–ä¸Šä¼ çš„ä¸´æ—¶æ–‡ä»¶å†…å®¹
                            from io import StringIO
                            stringio = StringIO(uploaded_file.getvalue().decode("utf-8"))
                            full_requirement += "\n\n--- [é™„åŠ æ–‡æ¡£å†…å®¹] ---\n" + stringio.read()
                        
                        st.info("æ¨¡å‹å’ŒçŸ¥è¯†åº“å·²å°±ç»ªï¼Œå¼€å§‹ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹...")

                        # 4. åˆ›å»ºå¹¶è°ƒç”¨RAGé“¾
                        rag_chain = create_rag_chain(retriever, llm, num_cases=num_cases)
                        
                        # åœ¨æ–°çš„spinnerä¸­æ‰§è¡Œinvoke
                        with st.spinner("ğŸ§  AI æ­£åœ¨æ€è€ƒä¸­ï¼Œè¯·ç¨å€™..."):
                            response = rag_chain.invoke(full_requirement)
                            st.session_state.generated_cases = response
                            st.rerun()

                    except Exception as e:
                        st.error(f"ç”Ÿæˆè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
                        # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ æ›´è¯¦ç»†çš„é”™è¯¯è¯Šæ–­ï¼Œæ¯”å¦‚æ£€æŸ¥OllamaæœåŠ¡æ˜¯å¦åœ¨è¿è¡Œ

    # --- å³ä¾§ä¸»åŒºåŸŸ ---
    st.subheader("ç”Ÿæˆç»“æœ")

    if st.session_state.generated_cases:
        # è¿™é‡Œå°†ç”¨äºæ˜¾ç¤ºç”Ÿæˆç»“æœçš„è§†å›¾
        st.success("æµ‹è¯•ç”¨ä¾‹å·²ç”Ÿæˆï¼")
        
        results = st.session_state.generated_cases
        
        # å°†Pydanticæ¨¡å‹è½¬æ¢ä¸ºPandas DataFrame
        try:
            test_cases_data = results.get('test_cases', [])
            if test_cases_data:
                df = pd.DataFrame([case for case in test_cases_data])
                
                # åˆ›å»ºç»“æœå±•ç¤ºçš„Tabs
                result_tabs = st.tabs(["è¡¨æ ¼è§†å›¾", "JSON æ•°æ®", "å¯¼å‡ºæ–‡ä»¶"])
                
                with result_tabs[0]:
                    st.dataframe(df, use_container_width=True)
                
                with result_tabs[1]:
                    st.json(results)
                    
                with result_tabs[2]:
                    # å¯¼å‡ºä¸ºExcel
                    excel_buffer = io.BytesIO()
                    df.to_excel(excel_buffer, index=False, engine='openpyxl')
                    st.download_button(
                        label="ä¸‹è½½ä¸º Excel",
                        data=excel_buffer,
                        file_name="test_cases.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    )

                    # å¯¼å‡ºä¸ºJSON
                    st.download_button(
                        label="ä¸‹è½½ä¸º JSON",
                        data=pd.io.json.dumps(results, indent=2),
                        file_name="test_cases.json",
                        mime="application/json",
                    )
            else:
                st.warning("AIæ¨¡å‹è¿”å›äº†ç©ºç»“æœï¼Œè¯·å°è¯•è°ƒæ•´æ‚¨çš„éœ€æ±‚æˆ–æ¨¡å‹å‚æ•°ã€‚")
                st.json(results) # æ˜¾ç¤ºåŸå§‹è¿”å›å†…å®¹ä»¥ä¾¿è°ƒè¯•

        except Exception as e:
            st.error("è§£æè¿”å›ç»“æœæ—¶å‡ºé”™ï¼Œè¯·æ£€æŸ¥LLMçš„è¾“å‡ºæ ¼å¼æ˜¯å¦æ­£ç¡®ã€‚")
            st.write("åŸå§‹è¾“å‡º:")
            st.write(results)

    else:
        st.info("è¯·åœ¨å·¦ä¾§è¾“å…¥éœ€æ±‚å¹¶ç‚¹å‡»ç”ŸæˆæŒ‰é’®ã€‚")


# --- é¡µé¢äºŒï¼šçŸ¥è¯†åº“ç®¡ç† ---
with tab_kb:
    st.header("ç®¡ç†æ‚¨çš„çŸ¥è¯†åº“æ–‡æ¡£")
    
    col1, col2 = st.columns([3, 1])
    with col1:
        st.info(f"å½“å‰çŠ¶æ€: **{st.session_state.knowledge_base_status['status']}** | "
                f"æ–‡æ¡£æ•°é‡: **{st.session_state.knowledge_base_status['doc_count']}** | "
                f"çŸ¥è¯†ç‰‡æ®µæ€»æ•°: **{st.session_state.knowledge_base_status['chunk_count']}**")
    with col2:
        if st.button("ğŸ”„ åˆ·æ–°çŠ¶æ€", use_container_width=True, help="æ¸…ç†æ‰€æœ‰å·²ä¸Šä¼ çš„æ–‡æ¡£å’Œæ•°æ®åº“ï¼Œé‡ç½®çŸ¥è¯†åº“çŠ¶æ€"):
            cleanup_directories()
            st.success("çŸ¥è¯†åº“å·²é‡ç½®ï¼")
            st.rerun()
            try:
                kb_manager = get_kb_manager()
                status = kb_manager.get_status()
                st.session_state.knowledge_base_status['status'] = "çŠ¶æ€å·²åˆ·æ–°"
                st.session_state.knowledge_base_status['doc_count'] = status['doc_count']
                st.session_state.knowledge_base_status['chunk_count'] = status['chunk_count']
                st.rerun()
            except Exception as e:
                st.error(f"åˆ·æ–°çŠ¶æ€æ—¶å‡ºé”™: {e}")

    uploaded_docs = st.file_uploader(
        "ä¸Šä¼ äº§å“æ–‡æ¡£ã€éœ€æ±‚æ–‡æ¡£ã€å†å²ç”¨ä¾‹ç­‰ (.pdf, .docx, .txt, .xlsx)", 
        accept_multiple_files=True,
        type=['pdf', 'docx', 'txt', 'xlsx']
    )
    
    if st.button("å¤„ç†ä¸Šä¼ çš„æ–‡æ¡£", use_container_width=True, type="primary"):
        if uploaded_docs:
            # Save files first
            for doc in uploaded_docs:
                file_path = os.path.join(KNOWLEDGE_BASE_DIR, doc.name)
                with open(file_path, "wb") as f:
                    f.write(doc.getbuffer())
            
            # Now, process them with a progress bar
            progress_bar = st.progress(0)
            status_text = st.empty()

            def progress_callback(progress, message):
                progress_bar.progress(progress / 100)
                status_text.info(message)

            try:
                kb_manager = get_kb_manager()
                kb_manager.load_and_process_documents(progress_callback=progress_callback)

                # æ›´æ–°çŠ¶æ€
                status = kb_manager.get_status()
                st.session_state.knowledge_base_status['status'] = "å¤„ç†å®Œæˆï¼Œå·²æ›´æ–°ï¼"
                st.session_state.knowledge_base_status['doc_count'] = status['doc_count']
                st.session_state.knowledge_base_status['chunk_count'] = status['chunk_count']
                
                st.success("æ–‡æ¡£å¤„ç†æˆåŠŸï¼çŸ¥è¯†åº“å·²æ›´æ–°ã€‚")
                st.rerun()
            except Exception as e:
                st.error(f"å¤„ç†æ–‡æ¡£æ—¶å‡ºé”™: {e}")
        else:
            st.warning("è¯·å…ˆä¸Šä¼ æ–‡æ¡£ã€‚")
        
    st.write("---")
    st.subheader("çŸ¥è¯†åº“æ¦‚è§ˆ")
    
    # æ˜¾ç¤ºçŸ¥è¯†åº“ä¸­çš„æ–‡ä»¶åˆ—è¡¨
    try:
        doc_list = os.listdir(KNOWLEDGE_BASE_DIR)
        if doc_list:
            st.write("å½“å‰çŸ¥è¯†åº“åŒ…å«ä»¥ä¸‹æ–‡æ¡£ï¼š")
            st.dataframe(pd.DataFrame(doc_list, columns=["æ–‡ä»¶å"]), use_container_width=True)
        else:
            st.write("çŸ¥è¯†åº“ä¸ºç©ºã€‚")
    except Exception as e:
        st.error(f"æ— æ³•è¯»å–çŸ¥è¯†åº“ç›®å½•ï¼š{e}")


# --- é¡µé¢ä¸‰ï¼šæ¨¡å‹è®¾ç½® ---
with tab_settings:
    st.header("é…ç½®æ‚¨çš„AIæ¨¡å‹")

    provider = st.selectbox("é€‰æ‹©æ¨¡å‹æä¾›å•†", ['Ollama', 'Gemini', 'OpenAICompatible'], index=0)
    st.session_state.model_settings['provider'] = provider

    if provider == 'Ollama':
        model_name = st.text_input("æ¨¡å‹åç§°", value=st.session_state.model_settings.get('model_name', 'qwen3:4b'))
        base_url = st.text_input("Ollama Base URL", value=st.session_state.model_settings.get('base_url', 'http://127.0.0.1:11434'))
        st.session_state.model_settings['model_name'] = model_name
        st.session_state.model_settings['base_url'] = base_url
    
    # ... (å…¶ä»–æä¾›å•†çš„è®¾ç½®)

    st.header("é…ç½®è¯­è¨€æ¨¡å‹ (LLM)")

    provider = st.selectbox(
        "é€‰æ‹©æ¨¡å‹æä¾›å•†",
        ('Ollama', 'Gemini', 'OpenAICompatible'),
        index=0,
        key='provider_select' 
    )

    api_key = ''
    base_url = ''

    if provider == 'Ollama':
        base_url = st.text_input("API Base URL", value=st.session_state.model_settings.get('base_url', 'http://127.0.0.1:11434'))
    elif provider == 'Gemini':
        api_key = st.text_input("Gemini API Key", type="password", value=st.session_state.model_settings.get('api_key', ''))
    elif provider == 'OpenAICompatible':
        base_url = st.text_input("API Base URL", value=st.session_state.model_settings.get('base_url', ''))
        api_key = st.text_input("API Key (å¯é€‰)", type="password", value=st.session_state.model_settings.get('api_key', ''))

    if st.button("ä¿å­˜è®¾ç½®", use_container_width=True):
        st.session_state.model_settings = {
            'provider': provider,
            'api_key': api_key,
            'base_url': base_url
        }
        st.success("æ¨¡å‹è®¾ç½®å·²ä¿å­˜ï¼")
        st.rerun()

    st.write("---")
    st.subheader("å½“å‰é…ç½®")
    st.json(st.session_state.model_settings)
