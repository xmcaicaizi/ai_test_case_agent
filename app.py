"""
Streamlit ä¸»åº”ç”¨æ–‡ä»¶
"""

import streamlit as st
import os
import pandas as pd
import io
import json

from config.config import config_manager

# --- é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="AI-TGA æ™ºèƒ½æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå¹³å°",
    page_icon="ğŸ§ª",
    layout="wide",
    initial_sidebar_state="expanded",
)

# --- ä¸»æ ‡é¢˜ ---
st.title("ğŸ¤– AI-TGA: æ™ºèƒ½æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå¹³å°")

# --- åˆå§‹åŒ– session state ---
# ç”¨äºåœ¨é¡µé¢åˆ·æ–°é—´ä¿æŒçŠ¶æ€

# æ‰€æœ‰å·²é…ç½®æ¨¡å‹çš„åˆ—è¡¨
if 'models' not in st.session_state:
    # å°è¯•ä»é…ç½®åŠ è½½ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
    saved_models = config_manager.get_config('models')
    if saved_models and isinstance(saved_models, list) and len(saved_models) > 0:
        st.session_state.models = saved_models
    else:
        st.session_state.models = [{
            'name': 'é»˜è®¤Ollamaæ¨¡å‹',
            'provider': 'Ollama',
            'model_name': 'qwen3:4b',
            'api_key': '',
            'base_url': 'http://127.0.0.1:11434'
        }]
        config_manager.set_config('models', st.session_state.models) # Save default if not present

# å½“å‰æ¿€æ´»æ¨¡å‹çš„åç§°
if 'active_model_name' not in st.session_state:
    st.session_state.active_model_name = config_manager.get_config('active_model_name') or (st.session_state.models[0]['name'] if st.session_state.models else None)

def get_model_settings_by_name(model_name):
    """æ ¹æ®åç§°ä»æ¨¡å‹åˆ—è¡¨ä¸­è·å–æ¨¡å‹é…ç½®"""
    if not model_name: return None
    for model in st.session_state.models:
        if model.get('name') == model_name:
            return model
    return None

# å½“å‰æ¿€æ´»æ¨¡å‹çš„è¯¦ç»†é…ç½®ï¼Œç”¨äºå‘åå…¼å®¹
# This ensures model_settings is always in sync with the active model
st.session_state.model_settings = get_model_settings_by_name(st.session_state.active_model_name) or {}
if 'embedding_model_name' not in st.session_state:
    st.session_state.embedding_model_name = config_manager.get_config('embedding_model_name', 'nomic-embed-text')

# --- å¸¸é‡å®šä¹‰ ---
KNOWLEDGE_BASE_DIR = "knowledge_files"
CHROMA_DB_DIR = os.path.join("db", "chroma_db")

# ç¡®ä¿ç›®å½•å­˜åœ¨
os.makedirs(KNOWLEDGE_BASE_DIR, exist_ok=True)
os.makedirs(CHROMA_DB_DIR, exist_ok=True)


# --- æ ¸å¿ƒé€»è¾‘å‡½æ•° ---
from core.knowledge_base import KnowledgeBaseManager

@st.cache_resource
def get_kb_manager():
    """ç¼“å­˜çŸ¥è¯†åº“ç®¡ç†å™¨å®ä¾‹"""
    return KnowledgeBaseManager(
        knowledge_base_dir=KNOWLEDGE_BASE_DIR, 
        chroma_db_dir=CHROMA_DB_DIR, 
        embedding_model_name=st.session_state.embedding_model_name
    )

# --- æ¸…ç†å‡½æ•° ---
def cleanup_directories():
    """æ¸…ç†çŸ¥è¯†åº“å’Œæ•°æ®åº“ç›®å½•"""
    import shutil
    # åœæ­¢å¹¶ç­‰å¾…æ–‡ä»¶é‡Šæ”¾
    if os.path.exists(KNOWLEDGE_BASE_DIR):
        shutil.rmtree(KNOWLEDGE_BASE_DIR, ignore_errors=True)
    if os.path.exists(CHROMA_DB_DIR):
        shutil.rmtree(CHROMA_DB_DIR, ignore_errors=True)
    
    # çŸ­æš‚ç­‰å¾…ä»¥ç¡®ä¿æ–‡ä»¶å¥æŸ„è¢«é‡Šæ”¾
    import time
    time.sleep(1)

    os.makedirs(KNOWLEDGE_BASE_DIR, exist_ok=True)
    os.makedirs(CHROMA_DB_DIR, exist_ok=True)
    
    # é‡ç½®ç¼“å­˜å’ŒçŠ¶æ€
    st.cache_resource.clear()
    st.session_state.knowledge_base_status = {
        "status": "å·²é‡ç½®",
        "doc_count": 0,
        "chunk_count": 0,
    }

if 'generated_cases' not in st.session_state:
    st.session_state.generated_cases = None

if 'knowledge_base_status' not in st.session_state:
    kb_manager = get_kb_manager()
    status = kb_manager.get_status()
    st.session_state.knowledge_base_status = {
        "status": "å·²åŠ è½½",
        "doc_count": status['doc_count'],
        "chunk_count": status['chunk_count'],
    }

# --- åˆ›å»ºä¸»é¡µé¢æ ‡ç­¾ ---
tab_generate, tab_kb, tab_settings = st.tabs([
    "ğŸ“„ ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹", 
    "ğŸ“š çŸ¥è¯†åº“ç®¡ç†", 
    "âš™ï¸ æ¨¡å‹è®¾ç½®"
])


# --- é¡µé¢ä¸€ï¼šç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ ---
with tab_generate:
    st.header("åœ¨è¿™é‡Œæ ¹æ®æ‚¨çš„éœ€æ±‚ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹")
    
    # --- ä¾§è¾¹æ  ---
    with st.sidebar:
        st.header("ç”Ÿæˆå‚æ•°é…ç½®")
        
        user_requirement = st.text_area("1. è¾“å…¥æ‚¨çš„éœ€æ±‚æè¿°", height=200, placeholder="ä¾‹å¦‚ï¼šè®¾è®¡ä¸€ä¸ªç”¨æˆ·ç™»å½•åŠŸèƒ½çš„æµ‹è¯•ç”¨ä¾‹ï¼Œéœ€è¦è€ƒè™‘æ­£å¸¸ç™»å½•ã€å¼‚å¸¸å¯†ç ã€é”å®šç­–ç•¥ç­‰åœºæ™¯ã€‚")
        
        uploaded_file = st.file_uploader("2. (å¯é€‰) ä¸Šä¼ éœ€æ±‚æ–‡æ¡£", type=['txt', 'pdf', 'docx', 'xlsx'])
        
        st.write("---")
        
        num_cases = st.slider("3. ç”Ÿæˆæœ€å¤§ç”¨ä¾‹æ•°é‡", min_value=1, max_value=20, value=5)
        
        temperature = st.slider("4. AI åˆ›é€ æ€§ (Temperature)", min_value=0.0, max_value=1.0, value=0.7, step=0.1, help="å€¼è¶Šé«˜ï¼Œç”Ÿæˆç»“æœè¶Šéšæœºå’Œæœ‰åˆ›æ„ï¼›å€¼è¶Šä½ï¼Œç»“æœè¶Šç¡®å®šå’Œä¿å®ˆã€‚")
        
        use_kb = st.checkbox("5. ä½¿ç”¨çŸ¥è¯†åº“å¢å¼ºç”Ÿæˆ", value=True)
        
        st.write("---")
        
        st.write("---")
        
        # æ¨¡å‹é€‰æ‹©
        st.subheader("LLM æ¨¡å‹")
        model_names = [m['name'] for m in st.session_state.models]
        
        if model_names:
            try:
                active_model_index = model_names.index(st.session_state.active_model_name)
            except (ValueError, TypeError):
                active_model_index = 0

            selected_model_name = st.selectbox(
                "é€‰æ‹©ä¸€ä¸ªæ¨¡å‹è¿›è¡Œç”Ÿæˆ",
                model_names,
                index=active_model_index,
                key='model_selector'
            )
            
            # æ˜¾ç¤ºå½“å‰é€‰ä¸­æ¨¡å‹çš„è¯¦ç»†ä¿¡æ¯
            current_model = get_model_settings_by_name(selected_model_name)
            if current_model and current_model.get('provider') == 'Qwen':
                from core.qwen_config import get_qwen_model_info
                model_info = get_qwen_model_info(current_model.get('model_name', ''))
                if model_info:
                    with st.expander("ğŸ“Š æ¨¡å‹è¯¦æƒ…", expanded=False):
                        col1, col2 = st.columns(2)
                        with col1:
                            st.write(f"**æè¿°**: {model_info.get('description', 'N/A')}")
                            st.write(f"**ä¸Šä¸‹æ–‡é•¿åº¦**: {model_info.get('context_length', 'N/A'):,} tokens")
                        with col2:
                            cost_info = model_info.get('cost_per_1k_tokens', {})
                            st.write(f"**è¾“å…¥æˆæœ¬**: Â¥{cost_info.get('input', 0)}/1K tokens")
                            st.write(f"**è¾“å‡ºæˆæœ¬**: Â¥{cost_info.get('output', 0)}/1K tokens")
                        
                        features = model_info.get('features', [])
                        if features:
                            st.write(f"**ç‰¹æ€§**: {', '.join(features)}")
            
            if selected_model_name != st.session_state.active_model_name:
                st.session_state.active_model_name = selected_model_name
                st.session_state.model_settings = get_model_settings_by_name(selected_model_name)
                config_manager.set_config('active_model_name', selected_model_name)
                st.rerun()
        else:
            st.warning("æ²¡æœ‰é…ç½®æ¨¡å‹ã€‚è¯·å‰å¾€'æ¨¡å‹è®¾ç½®'é¡µé¢æ·»åŠ ã€‚")

        st.subheader("Embedding æ¨¡å‹")
        st.info(f"å½“å‰æ¨¡å‹: **{st.session_state.embedding_model_name}**")

        from services.llm_service import generate_test_cases_with_llm
        from services.rag_service import generate_test_cases_with_rag

        if st.button("ğŸš€ ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹", type="primary", use_container_width=True):
            if not user_requirement and not uploaded_file:
                st.warning("è¯·è¾“å…¥éœ€æ±‚æè¿°æˆ–ä¸Šä¼ éœ€æ±‚æ–‡æ¡£ã€‚")
            else:
                with st.spinner("æ­£åœ¨å¤„ç†ä¸­..."):
                    try:
                        full_requirement = user_requirement
                        if uploaded_file:
                            from io import StringIO
                            stringio = StringIO(uploaded_file.getvalue().decode("utf-8"))
                            full_requirement += "\n\n--- [é™„åŠ æ–‡æ¡£å†…å®¹] ---\n" + stringio.read()

                        model_settings = st.session_state.model_settings
                        kb_manager = get_kb_manager()
                        
                        use_rag = use_kb and kb_manager.is_available and kb_manager.get_status()['doc_count'] > 0

                        if use_rag:
                            st.info("ä½¿ç”¨çŸ¥è¯†åº“å¢å¼ºç”Ÿæˆ...")
                            response = generate_test_cases_with_rag(model_settings, num_cases, full_requirement, kb_manager)
                        else:
                            st.info("ç›´æ¥ä½¿ç”¨LLMç”Ÿæˆ...")
                            response = generate_test_cases_with_llm(model_settings, num_cases, full_requirement)

                        st.session_state.generated_cases = response
                        st.rerun()

                    except Exception as e:
                        import traceback
                        error_trace = traceback.format_exc()
                        st.error(f"ç”Ÿæˆè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}\n\nè¯¦ç»†é”™è¯¯: {error_trace}")

    # --- å³ä¾§ä¸»åŒºåŸŸ ---
    st.subheader("ç”Ÿæˆç»“æœ")

    if st.session_state.generated_cases:
        # è¿™é‡Œå°†ç”¨äºæ˜¾ç¤ºç”Ÿæˆç»“æœçš„è§†å›¾
        st.success("æµ‹è¯•ç”¨ä¾‹å·²ç”Ÿæˆï¼")
        
        results = st.session_state.generated_cases
        
        # å°†Pydanticæ¨¡å‹è½¬æ¢ä¸ºPandas DataFrame
        try:
            # æ£€æŸ¥è¿”å›ç»“æœçš„ç±»å‹å’Œç»“æ„
            if isinstance(results, dict):
                test_cases_data = results.get('test_cases', [])
            elif hasattr(results, 'test_cases'):
                test_cases_data = results.test_cases
            else:
                # å¦‚æœç»“æœä¸æ˜¯é¢„æœŸæ ¼å¼ï¼Œå°è¯•ç›´æ¥ä½¿ç”¨
                test_cases_data = results if isinstance(results, list) else []
            
            if test_cases_data:
                # å°†Pydanticå¯¹è±¡è½¬æ¢ä¸ºå­—å…¸ï¼ˆå¦‚æœéœ€è¦ï¼‰
                if hasattr(test_cases_data[0], 'dict'):
                    df_data = [case.dict() if hasattr(case, 'dict') else case for case in test_cases_data]
                else:
                    df_data = test_cases_data
                
                df = pd.DataFrame(df_data)
                
                # åˆ›å»ºç»“æœå±•ç¤ºçš„Tabs
                result_tabs = st.tabs(["è¡¨æ ¼è§†å›¾", "JSON æ•°æ®", "å¯¼å‡ºæ–‡ä»¶"])
                
                with result_tabs[0]:
                    st.dataframe(df, use_container_width=True)
                
                with result_tabs[1]:
                    st.json(results)
                    
                with result_tabs[2]:
                    # å¯¼å‡ºä¸ºExcel
                    excel_buffer = io.BytesIO()
                    df.to_excel(excel_buffer, index=False, engine='openpyxl')
                    st.download_button(
                        label="ä¸‹è½½ä¸º Excel",
                        data=excel_buffer,
                        file_name="test_cases.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    )

                    # å¯¼å‡ºä¸ºJSON
                    st.download_button(
                        label="ä¸‹è½½ä¸º JSON",
                        data=pd.io.json.dumps(results, indent=2),
                        file_name="test_cases.json",
                        mime="application/json",
                    )
            else:
                st.warning("AIæ¨¡å‹è¿”å›äº†ç©ºç»“æœï¼Œè¯·å°è¯•è°ƒæ•´æ‚¨çš„éœ€æ±‚æˆ–æ¨¡å‹å‚æ•°ã€‚")
                st.write("è°ƒè¯•ä¿¡æ¯ - åŸå§‹è¿”å›ç»“æœ:")
                st.json(results) # æ˜¾ç¤ºåŸå§‹è¿”å›å†…å®¹ä»¥ä¾¿è°ƒè¯•

        except Exception as e:
            st.error("è§£æè¿”å›ç»“æœæ—¶å‡ºé”™ï¼Œè¯·æ£€æŸ¥LLMçš„è¾“å‡ºæ ¼å¼æ˜¯å¦æ­£ç¡®ã€‚")
            st.write("é”™è¯¯è¯¦æƒ…:", str(e))
            st.write("è°ƒè¯•ä¿¡æ¯ - åŸå§‹è¾“å‡º:")
            st.write(results)
            st.write("ç»“æœç±»å‹:", type(results))
            
            # å°è¯•æ˜¾ç¤ºéƒ¨åˆ†å¯ç”¨ä¿¡æ¯
            try:
                if hasattr(results, '__dict__'):
                    st.write("å¯¹è±¡å±æ€§:", list(results.__dict__.keys()))
                elif isinstance(results, dict):
                    st.write("å­—å…¸é”®:", list(results.keys()))
            except:
                pass

    else:
        st.info("è¯·åœ¨å·¦ä¾§è¾“å…¥éœ€æ±‚å¹¶ç‚¹å‡»ç”ŸæˆæŒ‰é’®ã€‚")


# --- é¡µé¢äºŒï¼šçŸ¥è¯†åº“ç®¡ç† ---
with tab_kb:
    st.header("ç®¡ç†æ‚¨çš„çŸ¥è¯†åº“æ–‡æ¡£")

    # --- åµŒå…¥æ¨¡å‹é…ç½® ---
    st.subheader("åµŒå…¥æ¨¡å‹é…ç½®")
    kb_manager = get_kb_manager()
    
    # ä» session_state æˆ–é»˜è®¤å€¼åŠ è½½ embedding_model_name
    if 'embedding_model_name' not in st.session_state:
        st.session_state.embedding_model_name = kb_manager.embedding_model_name

    # ä½¿ç”¨ session_state ä¸­çš„å€¼åˆ›å»ºè¾“å…¥æ¡†
    embedding_model_name = st.text_input(
        "Ollama åµŒå…¥æ¨¡å‹åç§°", 
        value=st.session_state.embedding_model_name,
        key="embedding_model_input"
    )

    # æ›´æ–° session_state
    st.session_state.embedding_model_name = embedding_model_name

    col1, col2 = st.columns([1, 4])
    with col1:
        if st.button("æµ‹è¯•å¹¶ä¿å­˜æ¨¡å‹", use_container_width=True):
            with st.spinner(f"æ­£åœ¨æµ‹è¯•æ¨¡å‹ '{embedding_model_name}'..."):
                # æ›´æ–° KnowledgeBaseManager ä¸­çš„æ¨¡å‹åç§°
                kb_manager.embedding_model_name = embedding_model_name
                # æµ‹è¯•è¿æ¥
                if kb_manager._test_ollama_connection(model_name=embedding_model_name):
                    st.success(f"æ¨¡å‹ '{embedding_model_name}' è¿æ¥æˆåŠŸï¼å·²ä¿å­˜ä¸ºé»˜è®¤æ¨¡å‹ã€‚")
                    # æ¸…é™¤ç¼“å­˜ä»¥ä½¿ç”¨æ–°æ¨¡å‹é‡æ–°åŠ è½½
                    st.cache_resource.clear()
                else:
                    st.error(f"æ¨¡å‹ '{embedding_model_name}' è¿æ¥å¤±è´¥ã€‚è¯·æ£€æŸ¥æ¨¡å‹åç§°å’ŒOllamaæœåŠ¡æ˜¯å¦æ­£ç¡®ã€‚")
    
    st.markdown("---_")

    # --- çŸ¥è¯†åº“æ“ä½œ ---
    st.subheader("çŸ¥è¯†åº“æ“ä½œ")
    col1, col2 = st.columns([3, 1])
    with col1:
        st.info(f"å½“å‰çŠ¶æ€: **{st.session_state.knowledge_base_status['status']}** | "
                f"æ–‡æ¡£æ•°é‡: **{st.session_state.knowledge_base_status['doc_count']}** | "
                f"çŸ¥è¯†ç‰‡æ®µæ€»æ•°: **{st.session_state.knowledge_base_status['chunk_count']}**")
    with col2:
        if st.button("ğŸ”„ é‡ç½®çŸ¥è¯†åº“", use_container_width=True, help="æ¸…ç†æ‰€æœ‰å·²ä¸Šä¼ çš„æ–‡æ¡£å’Œæ•°æ®åº“ï¼Œé‡ç½®çŸ¥è¯†åº“çŠ¶æ€"):
            cleanup_directories()
            st.success("çŸ¥è¯†åº“å·²é‡ç½®ï¼")
            st.rerun()

    uploaded_docs = st.file_uploader(
        "ä¸Šä¼ äº§å“æ–‡æ¡£ã€éœ€æ±‚æ–‡æ¡£ã€å†å²ç”¨ä¾‹ç­‰ (.pdf, .docx, .txt, .xlsx)", 
        accept_multiple_files=True,
        type=['pdf', 'docx', 'txt', 'xlsx']
    )
    
    if st.button("å¤„ç†ä¸Šä¼ çš„æ–‡æ¡£", use_container_width=True, type="primary"):
        if uploaded_docs:
            kb_manager = get_kb_manager()
            kb_manager.handle_doc_upload(uploaded_docs)
        else:
            st.warning("è¯·å…ˆä¸Šä¼ æ–‡æ¡£ã€‚")
        
    st.write("---")
    st.subheader("çŸ¥è¯†åº“æ¦‚è§ˆ")
    
    # æ˜¾ç¤ºçŸ¥è¯†åº“ä¸­çš„æ–‡ä»¶åˆ—è¡¨
    try:
        doc_list = os.listdir(KNOWLEDGE_BASE_DIR)
        if doc_list:
            st.write("å½“å‰çŸ¥è¯†åº“åŒ…å«ä»¥ä¸‹æ–‡æ¡£ï¼š")
            st.dataframe(pd.DataFrame(doc_list, columns=["æ–‡ä»¶å"]), use_container_width=True)
        else:
            st.write("çŸ¥è¯†åº“ä¸ºç©ºã€‚")
    except Exception as e:
        st.error(f"æ— æ³•è¯»å–çŸ¥è¯†åº“ç›®å½•ï¼š{e}")


# --- é¡µé¢ä¸‰ï¼šæ¨¡å‹è®¾ç½® ---
with tab_settings:
    st.header("ç®¡ç†æ‚¨çš„AIæ¨¡å‹")

    # --- æ¨¡å‹åˆ—è¡¨ --- #
    st.subheader("å·²é…ç½®çš„æ¨¡å‹")
    if not st.session_state.models:
        st.info("æ‚¨è¿˜æ²¡æœ‰é…ç½®ä»»ä½•æ¨¡å‹ã€‚è¯·ä½¿ç”¨ä¸‹é¢çš„è¡¨å•æ·»åŠ ä¸€ä¸ªæ–°æ¨¡å‹ã€‚")
    else:
        for i, model in enumerate(st.session_state.models):
            with st.expander(f"**{model.get('name', f'æ¨¡å‹ {i+1}')}** (`{model.get('provider')}` - `{model.get('model_name')}`)"):
                st.text(f"æä¾›å•†: {model.get('provider')}")
                st.text(f"æ¨¡å‹åç§°: {model.get('model_name')}")
                st.text(f"Base URL: {model.get('base_url', 'N/A')}")
                api_key_display = "*" * 10 if model.get('api_key') else "æœªè®¾ç½®"
                st.text(f"API Key: {api_key_display}")
                
                col1, col2, col3 = st.columns([1,1,5])
                with col1:
                    if st.button("è®¾ä¸ºæ´»åŠ¨æ¨¡å‹", key=f"activate_{i}", use_container_width=True):
                        st.session_state.active_model_name = model['name']
                        st.session_state.model_settings = model
                        config_manager.set_config('active_model_name', model['name'])
                        st.success(f"æ¨¡å‹ '{model['name']}' å·²è¢«æ¿€æ´»ï¼")
                        st.rerun()
                with col2:
                    if st.button("åˆ é™¤", key=f"delete_{i}", type="secondary", use_container_width=True):
                        # If deleting the active model, reset active model to the first one if possible
                        if st.session_state.active_model_name == model['name']:
                            st.session_state.active_model_name = st.session_state.models[0]['name'] if len(st.session_state.models) > 1 else None
                            config_manager.set_config('active_model_name', st.session_state.active_model_name)
                        
                        st.session_state.models.pop(i)
                        config_manager.set_config('models', st.session_state.models)
                        st.success(f"æ¨¡å‹ '{model.get('name')}' å·²è¢«åˆ é™¤ï¼")
                        st.rerun()

    st.write("---")

    # --- é€šä¹‰åƒé—®å¿«é€Ÿé…ç½® --- #
    st.subheader("ğŸš€ é€šä¹‰åƒé—®å¿«é€Ÿé…ç½®")
    with st.expander("ç‚¹å‡»å±•å¼€é€šä¹‰åƒé—®æ¨¡å‹é…ç½®", expanded=False):
        st.info("é€šä¹‰åƒé—®æ”¯æŒ OpenAI Compatible APIï¼Œåªéœ€è¦æ‚¨çš„ API Key å³å¯å¿«é€Ÿé…ç½®ã€‚")
        
        qwen_api_key = st.text_input(
            "é€šä¹‰åƒé—® API Key", 
            type="password",
            placeholder="sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx",
            help="è¯·åœ¨é˜¿é‡Œäº‘ç™¾ç‚¼æ§åˆ¶å°è·å–æ‚¨çš„ API Key"
        )
        
        if qwen_api_key:
            from core.qwen_config import get_qwen_model_list, validate_qwen_api_key
            
            if validate_qwen_api_key(qwen_api_key):
                st.success("âœ… API Key æ ¼å¼éªŒè¯é€šè¿‡")
                
                qwen_models = get_qwen_model_list()
                selected_qwen_models = st.multiselect(
                    "é€‰æ‹©è¦æ·»åŠ çš„é€šä¹‰åƒé—®æ¨¡å‹",
                    options=[model["model_name"] for model in qwen_models],
                    default=["qwen-plus"],
                    format_func=lambda x: next((model["display_name"] + f" - {model['description']}" for model in qwen_models if model["model_name"] == x), x)
                )
                
                if st.button("ğŸ¯ ä¸€é”®æ·»åŠ é€‰ä¸­çš„é€šä¹‰åƒé—®æ¨¡å‹", type="primary"):
                    added_count = 0
                    for model_name in selected_qwen_models:
                        model_info = next((model for model in qwen_models if model["model_name"] == model_name), None)
                        if model_info:
                            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒçš„æ¨¡å‹
                            existing_model = next((m for m in st.session_state.models if m.get('provider') == 'Qwen' and m.get('model_name') == model_name), None)
                            if not existing_model:
                                new_model = {
                                    'name': model_info["display_name"],
                                    'provider': 'Qwen',
                                    'model_name': model_name,
                                    'api_key': qwen_api_key,
                                    'base_url': 'https://dashscope.aliyuncs.com/compatible-mode/v1',
                                    'description': model_info["description"],
                                    'context_length': model_info["context_length"],
                                    'cost_info': model_info["cost_info"]
                                }
                                st.session_state.models.append(new_model)
                                added_count += 1
                    
                    if added_count > 0:
                        config_manager.set_config('models', st.session_state.models)
                        
                        # å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡æ·»åŠ æ¨¡å‹ï¼Œè®¾ä¸ºæ´»åŠ¨æ¨¡å‹
                        if len(st.session_state.models) == added_count:
                            st.session_state.active_model_name = st.session_state.models[0]['name']
                            config_manager.set_config('active_model_name', st.session_state.models[0]['name'])
                        
                        st.success(f"âœ… æˆåŠŸæ·»åŠ  {added_count} ä¸ªé€šä¹‰åƒé—®æ¨¡å‹ï¼")
                        st.rerun()
                    else:
                        st.warning("æ‰€é€‰æ¨¡å‹å·²å­˜åœ¨ï¼Œæœªæ·»åŠ æ–°æ¨¡å‹ã€‚")
            else:
                st.error("âŒ API Key æ ¼å¼ä¸æ­£ç¡®ï¼Œè¯·æ£€æŸ¥åé‡è¯•")

    st.write("---")

    # --- æ·»åŠ /ç¼–è¾‘æ¨¡å‹è¡¨å• --- #
    st.subheader("æ‰‹åŠ¨æ·»åŠ æ¨¡å‹")
    with st.form(key="add_model_form"):
        name = st.text_input("æ¨¡å‹åˆ«å*", placeholder="ä¾‹å¦‚ï¼šæˆ‘çš„æœ¬åœ°Qwenæ¨¡å‹")
        provider = st.selectbox("é€‰æ‹©æ¨¡å‹æä¾›å•†*", ('Ollama', 'Qwen', 'Doubao', 'Gemini', 'OpenAICompatible'))
        
        # æ ¹æ®é€‰æ‹©çš„æä¾›å•†æ˜¾ç¤ºä¸åŒçš„æç¤º
        if provider == 'Qwen':
            model_name = st.selectbox("é€šä¹‰åƒé—®æ¨¡å‹*", ['qwen-plus', 'qwen-turbo', 'qwen-max', 'qwen-plus-latest', 'qwen-turbo-latest', 'qwen-max-latest'])
            base_url = st.text_input("Base URL", value="https://dashscope.aliyuncs.com/compatible-mode/v1")
        elif provider == 'Ollama':
            model_name = st.text_input("æ¨¡å‹åç§°*", placeholder="ä¾‹å¦‚ï¼šqwen3:4b, llama3:8b")
            base_url = st.text_input("Base URL", value="http://127.0.0.1:11434")
        else:
            model_name = st.text_input("æ¨¡å‹åç§°*", placeholder="ä¾‹å¦‚ï¼šgpt-4, claude-3")
            base_url = st.text_input("Base URL", placeholder="ä¾‹å¦‚ï¼šhttps://api.openai.com/v1")
        
        api_key = st.text_input("API Key", type="password")

        submitted = st.form_submit_button("æ·»åŠ æ¨¡å‹")
        if submitted:
            if not name or not provider or not model_name:
                st.error("æ¨¡å‹åˆ«åã€æä¾›å•†å’Œæ¨¡å‹åç§°æ˜¯å¿…å¡«é¡¹ã€‚")
            else:
                new_model = {
                    'name': name,
                    'provider': provider,
                    'model_name': model_name,
                    'api_key': api_key,
                    'base_url': base_url
                }
                st.session_state.models.append(new_model)
                config_manager.set_config('models', st.session_state.models)
                
                # If it's the first model added, set it as active
                if len(st.session_state.models) == 1:
                    st.session_state.active_model_name = name
                    config_manager.set_config('active_model_name', name)

                st.success(f"æ¨¡å‹ '{name}' å·²æˆåŠŸæ·»åŠ ï¼")
                st.rerun()
